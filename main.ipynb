{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37230b5a",
   "metadata": {},
   "source": [
    "#### Realizaremos un modelo que identifique si un comentario es positivo o negativo con TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577544c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e0be693",
   "metadata": {},
   "source": [
    "1. importamos la librer√≠as que nos permitir√° hacer un buen manejo de lso datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas: Librer√≠a para manipulaci√≥n y an√°lisis de datos estructurados (DataFrames, CSV, etc.)\n",
    "import pandas as pd  \n",
    "\n",
    "# NumPy: Manejo eficiente de arreglos num√©ricos y c√°lculos matem√°ticos avanzados\n",
    "import numpy as np  \n",
    "\n",
    "# Matplotlib: Creaci√≥n de gr√°ficos y visualizaci√≥n de datos\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Deep Translator: Traducci√≥n autom√°tica de textos utilizando Google Translate\n",
    "from deep_translator import GoogleTranslator  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f057bc",
   "metadata": {},
   "source": [
    "2. ahora importaremos la librer√≠a que nos permitir√° hacer el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1408234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow: Framework de aprendizaje autom√°tico que permite construir y entrenar redes neuronales\n",
    "import tensorflow as tf \n",
    "\n",
    "# Tokenizer: Convierte textos en secuencias num√©ricas para que el modelo las procese\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  \n",
    "\n",
    "# pad_sequences: Asegura que todas las secuencias tengan la misma longitud agregando ceros si es necesario\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  \n",
    "\n",
    "# train_test_split: Divide los datos en conjuntos de entrenamiento y prueba para evaluar el rendimiento del modelo\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# load_model: Carga un modelo previamente entrenado desde un archivo\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d39fa",
   "metadata": {},
   "source": [
    "3. cargamos el DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cdef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga un archivo CSV en un DataFrame de Pandas\n",
    "df = pd.read_csv('sentiment-analysis.csv')  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965cd1c",
   "metadata": {},
   "source": [
    "4. traducimos todo los datos de la columna Text para trabajar con datos en espa√±ol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduce cada texto autom√°ticamente al espa√±ol\n",
    "df['Text'] = df['Text'].apply(lambda x: GoogleTranslator(source='auto', target='es').translate(x))  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame para verificar la traducci√≥n\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0efc011",
   "metadata": {},
   "source": [
    "5. una ves traducido los textos ahora hay que traducir las forma de sentimiento ( parte opcional )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduce cada etiqueta de sentimiento al espa√±ol\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: GoogleTranslator(source='auto', target='es').translate(x))  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame para verificar la traducci√≥n\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71bfa81",
   "metadata": {},
   "source": [
    "6. por ultimo traducimos de donde es el usuario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e67189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduce autom√°ticamente cada ubicaci√≥n al espa√±ol\n",
    "df['Location'] = df['Location'].apply(lambda x: GoogleTranslator(source='auto', target='es').translate(x))  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame para verificar la traducci√≥n\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b559e129",
   "metadata": {},
   "source": [
    "7. exportamos el DataFrame a csv para usarlo para el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda el DataFrame como un archivo CSV sin incluir el √≠ndice\n",
    "df.to_csv('an√°lisis_de_sentimientos.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad4f75",
   "metadata": {},
   "source": [
    "8. una ves traducida y formateada al lenguaje que queremos lo leemos de vuelta para para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el archivo CSV en un DataFrame de Pandas\n",
    "df = pd.read_csv('an√°lisis_de_sentimientos.csv')  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f986b15a",
   "metadata": {},
   "source": [
    "9. convertimos el tipo de sentimiento en Positivo a 1 Negativo a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb6b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte las etiquetas de sentimiento de texto a valores num√©ricos (1 para positivo, 0 para negativo)\n",
    "df['Sentiment'] = df['Sentiment'].map({'Positivo': 1, 'Negativo': 0})  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame para verificar la conversi√≥n\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09961c8d",
   "metadata": {},
   "source": [
    "10. debemos hacer que los valores del la columna Text se conviertan a n√∫meros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define un tokenizador que usa hasta 5000 palabras y asigna \"<OOV>\" a palabras desconocidas\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")  \n",
    "\n",
    "# Ajusta el tokenizador usando los textos del dataset\n",
    "tokenizer.fit_on_texts(df[\"Text\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983be0f8",
   "metadata": {},
   "source": [
    "11. convertimos los valores de Text en una secuencia num√©rica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd87581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los textos en secuencias num√©ricas\n",
    "sequences = tokenizer.texts_to_sequences(df['Text'])  \n",
    "\n",
    "# Muestra las primeras cinco secuencias generadas\n",
    "sequences[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta la longitud de todas las secuencias agregando ceros al final cuando sea necesario\n",
    "padded_sequences = pad_sequences(sequences, padding='post')\n",
    "\n",
    "# Muestra las primeras cinco secuencias despu√©s de aplicar el padding\n",
    "padded_sequences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248a950",
   "metadata": {},
   "source": [
    "12. Divisi√≥n en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sequences,  # üîπ Datos de entrada: secuencias num√©ricas de los textos procesados\n",
    "    df[\"Sentiment\"],  # üîπ Etiquetas de salida: 1 para positivo, 0 para negativo\n",
    "    test_size=0.2,  # üîπ Reservamos el 20% de los datos para prueba y el 80% para entrenamiento\n",
    "    random_state=42  # üîπ Usamos una semilla aleatoria para asegurar que la divisi√≥n sea reproducible en cada ejecuci√≥n\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530cf745",
   "metadata": {},
   "source": [
    "13. Construcci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Creaci√≥n del modelo secuencial\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    #  Capa de Embedding: convierte palabras en vectores num√©ricos\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=5000,  # Define el tama√±o del vocabulario (m√°ximo 5000 palabras √∫nicas)\n",
    "        output_dim=16,  # Especifica la dimensi√≥n de los vectores de palabras (cada palabra se representar√° con 16 valores)\n",
    "        input_length=padded_sequences.shape[1]  # Define la longitud esperada de las secuencias de entrada\n",
    "    ),\n",
    "\n",
    "    #  Global Average Pooling: reduce la dimensi√≥n del Embedding promediando los valores\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "    #  Capa completamente conectada (oculta) con 16 neuronas y activaci√≥n ReLU\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "\n",
    "    #  Capa de salida con una √∫nica neurona y activaci√≥n sigmoide para clasificaci√≥n binaria\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b751e80",
   "metadata": {},
   "source": [
    "14. compilamos el modelo y mostramos el resumen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554513af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Compilamos el modelo antes de entrenarlo\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',  #  Funci√≥n de p√©rdida utilizada en clasificaci√≥n binaria; mide la diferencia entre la predicci√≥n y la etiqueta real\n",
    "    optimizer='adam',  #  Optimizador Adam ajusta los pesos del modelo para mejorar su precisi√≥n\n",
    "    metrics=['accuracy']  #  Se usa la m√©trica de precisi√≥n para evaluar el rendimiento durante el entrenamiento\n",
    ")\n",
    "\n",
    "# üîπ Muestra la estructura del modelo, incluyendo el n√∫mero de capas y par√°metros\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3727a017",
   "metadata": {},
   "source": [
    "15. entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52263f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Entrenamos el modelo con los datos de entrenamiento\n",
    "history = model.fit(\n",
    "    X_train,  #  Datos de entrada para entrenamiento (secuencias de texto numerizadas)\n",
    "    y_train,  #  Etiquetas de salida para entrenamiento (1 = positivo, 0 = negativo)\n",
    "    epochs=100,  #  N√∫mero de √©pocas (veces que el modelo ver√° los datos para aprender)\n",
    "    validation_data=(X_test, y_test)  # üìå Datos de validaci√≥n para evaluar el rendimiento del modelo durante el entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbdb603",
   "metadata": {},
   "source": [
    "16. Evaluaci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Evaluamos el modelo con los datos de prueba para medir su rendimiento\n",
    "loss, accuracy = model.evaluate(\n",
    "    X_test,  #  Conjunto de datos de prueba (secuencias num√©ricas)\n",
    "    y_test   #  Etiquetas reales de prueba (1 = positivo, 0 = negativo)\n",
    ")\n",
    "\n",
    "# üîπ Imprimimos la precisi√≥n del modelo con dos decimales\n",
    "print(f\"Accuracy: {accuracy:.2f}\")  #  Muestra la precisi√≥n en porcentaje, indicando qu√© tan bien predice el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea805a44",
   "metadata": {},
   "source": [
    "17. hacemos el gr√°fico de perdida para para saber como le fue al modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d31be",
   "metadata": {},
   "source": [
    "#### Este gr√°fico representa la evoluci√≥n de la p√©rdida del modelo durante el entrenamiento y la validaci√≥n a lo largo de las √©pocas.\n",
    "\n",
    "- Eje X (Epochs): Muestra el n√∫mero de √©pocas, es decir, la cantidad de veces que el modelo ha procesado el conjunto de datos para ajustar sus par√°metros.\n",
    "\n",
    "- Eje Y (Loss): Representa el valor de la p√©rdida, que indica qu√© tan bien (o mal) el modelo est√° prediciendo los resultados. Un menor valor de p√©rdida \n",
    "significa un mejor ajuste del modelo.\n",
    "\n",
    "- L√≠nea azul (\"P√©rdida de Entrenamiento\"): Indica c√≥mo disminuye la p√©rdida en el conjunto de entrenamiento a medida que el modelo aprende.\n",
    "\n",
    "- L√≠nea roja (\"P√©rdida de Validaci√≥n\"): Muestra la p√©rdida en el conjunto de validaci√≥n, que eval√∫a el rendimiento del modelo en datos que no ha visto \n",
    "durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la lista de √©pocas basada en la cantidad de iteraciones del entrenamiento\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Configuramos el tama√±o de la figura para mejorar la visualizaci√≥n\n",
    "plt.figure(figsize=(30, 8))\n",
    "\n",
    "# Creamos el primer gr√°fico: evoluci√≥n de la p√©rdida durante el entrenamiento y la validaci√≥n\n",
    "plt.subplot(1, 2, 1)  # Dividimos la figura en 1 fila y 2 columnas, seleccionando la primera celda\n",
    "plt.plot(epochs, history.history['loss'], 'bo-', label='P√©rdida de Entrenamiento')  # Trazamos la p√©rdida del conjunto de entrenamiento\n",
    "plt.plot(epochs, history.history['val_loss'], 'r*-', label='P√©rdida de Validaci√≥n')  # Trazamos la p√©rdida del conjunto de validaci√≥n\n",
    "plt.xlabel('Epochs')  # Etiqueta del eje X (√©pocas del entrenamiento)\n",
    "plt.ylabel('Loss')  # Etiqueta del eje Y (valor de p√©rdida)\n",
    "plt.title('Training and Validation Loss')  # T√≠tulo del gr√°fico\n",
    "plt.legend()  # Muestra la leyenda para diferenciar las l√≠neas de entrenamiento y validaci√≥n\n",
    "plt.grid()  # Agrega una cuadr√≠cula para mejorar la visualizaci√≥n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa956d6c",
   "metadata": {},
   "source": [
    "18. ahora hacemos el gr√°fico de precision "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a17178",
   "metadata": {},
   "source": [
    "#### Este gr√°fico representa la evoluci√≥n de la precisi√≥n del modelo durante el entrenamiento y la validaci√≥n a lo largo de las √©pocas.\n",
    "\n",
    "- Eje X (√©pocas): Indica el n√∫mero de ciclos completos que el modelo ha realizado con los datos de entrenamiento. Cada √©poca representa una pasada completa por el conjunto de datos.\n",
    "\n",
    "- Eje Y (nivel de precisi√≥n): Muestra la precisi√≥n del modelo, es decir, la proporci√≥n de predicciones correctas con respecto al total de ejemplos evaluados.\n",
    "\n",
    "- L√≠nea azul (\"Precisi√≥n de Entrenamiento\"): Representa c√≥mo mejora la precisi√≥n del modelo en el conjunto de datos utilizados para el entrenamiento. En general, esta l√≠nea deber√≠a aumentar con cada √©poca.\n",
    "\n",
    "- L√≠nea roja (\"Precisi√≥n de Validaci√≥n\"): Indica la precisi√≥n del modelo al evaluar datos nuevos que no ha visto antes. Si esta l√≠nea comienza a disminuir mientras la precisi√≥n de entrenamiento sigue aumentando, puede ser una se√±al de sobreajuste.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b96584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el tama√±o de la figura para mejorar la visualizaci√≥n de la precisi√≥n\n",
    "plt.figure(figsize=(30, 8))\n",
    "\n",
    "# Creamos el segundo gr√°fico: evoluci√≥n de la precisi√≥n durante el entrenamiento y la validaci√≥n\n",
    "plt.subplot(1, 2, 2)  # Dividimos la figura en 1 fila y 2 columnas, seleccionando la segunda celda\n",
    "plt.plot(epochs, history.history['accuracy'], 'bo-', label='Precisi√≥n de Entrenamiento')  # Trazamos la precisi√≥n del conjunto de entrenamiento\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r*-', label='Precisi√≥n de Validaci√≥n')  # Trazamos la precisi√≥n del conjunto de validaci√≥n\n",
    "plt.xlabel('√©pocas')  # Etiqueta del eje X (√©pocas de entrenamiento)\n",
    "plt.ylabel('nivel de precisi√≥n')  # Etiqueta del eje Y (nivel de precisi√≥n)\n",
    "plt.title('Precision de entrenamiento y validaciones ')  # T√≠tulo del gr√°fico\n",
    "plt.legend()  # Muestra la leyenda para diferenciar las l√≠neas de entrenamiento y validaci√≥n\n",
    "plt.grid()  # Agrega una cuadr√≠cula para mejorar la lectura de los valores\n",
    "\n",
    "# Mostramos el gr√°fico en pantalla\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f8479",
   "metadata": {},
   "source": [
    "19. hacemos unos textos positivos y negativos para hacer uan predicci√≥n de prueba final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59aa4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un nuevo texto positivo para evaluar el modelo\n",
    "new_text_positive = \"Me encanta este producto, es incre√≠ble y funciona perfectamente.\"\n",
    "\n",
    "# Convertimos el texto en una secuencia num√©rica utilizando el tokenizador entrenado\n",
    "new_sequence = tokenizer.texts_to_sequences([new_text_positive])\n",
    "\n",
    "# Aplicamos padding a la secuencia para igualar la longitud esperada por el modelo\n",
    "new_padded_positive = pad_sequences(\n",
    "    new_sequence,  # Secuencia num√©rica generada a partir del texto\n",
    "    padding=\"post\",  # Agrega ceros al final si la secuencia es m√°s corta que el tama√±o esperado\n",
    "    maxlen=padded_sequences.shape[1]  # Define la longitud m√°xima basada en las secuencias utilizadas en el entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un nuevo texto negativo para evaluar el modelo\n",
    "new_text_negative = \"muy malo el producto no me gust√≥ para nada\"\n",
    "\n",
    "# Convertimos el texto en una secuencia num√©rica utilizando el tokenizador entrenado\n",
    "new_sequence = tokenizer.texts_to_sequences([new_text_negative])\n",
    "\n",
    "# Aplicamos padding a la secuencia para igualar la longitud esperada por el modelo\n",
    "new_padded_negative = pad_sequences(\n",
    "    new_sequence,  # Secuencia num√©rica generada a partir del texto\n",
    "    padding=\"post\",  # Agrega ceros al final si la secuencia es m√°s corta que el tama√±o esperado\n",
    "    maxlen=padded_sequences.shape[1]  # Define la longitud m√°xima basada en las secuencias utilizadas en el entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e203e55",
   "metadata": {},
   "source": [
    "20. hacemos la predicci√≥n de los dos comentarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d319869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la predicci√≥n utilizando el modelo entrenado\n",
    "prediction = model.predict(new_padded_positive)  # Genera una probabilidad de que el texto tenga un sentimiento positivo\n",
    "\n",
    "# Interpretamos la predicci√≥n: si el resultado es mayor a 0.5, se considera positivo; de lo contrario, negativo\n",
    "sentimiento = \"Positivo\" if prediction[0] > 0.5 else \"Negativo\"\n",
    "\n",
    "# Imprimimos el texto analizado junto con el sentimiento estimado y la probabilidad calculada\n",
    "print(f'\"{new_text_positive}\" ‚Üí Sentimiento: {sentimiento} ({prediction[0][0]:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la predicci√≥n utilizando el modelo entrenado\n",
    "prediction = model.predict(new_padded_negative)  # Genera una probabilidad de que el texto tenga un sentimiento positivo\n",
    "\n",
    "# Interpretamos la predicci√≥n: si el resultado es mayor a 0.5, se considera positivo; de lo contrario, negativo\n",
    "sentimiento = \"Positivo\" if prediction[0] > 0.5 else \"Negativo\"\n",
    "\n",
    "# Imprimimos el texto analizado junto con el sentimiento estimado y la probabilidad calculada\n",
    "print(f'\"{new_text_negative}\" ‚Üí Sentimiento: {sentimiento} ({prediction[0][0]:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b8d87",
   "metadata": {},
   "source": [
    "21. exportamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5254bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo en formato HDF5 (.h5)\n",
    "model.save(\"modelo_sentimientos.h5\")  \n",
    "# Guarda toda la arquitectura, pesos y configuraci√≥n del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1161cfc",
   "metadata": {},
   "source": [
    "22. cargamos el modelo para probarlo de vuelta asi sabemos si funciona correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo guardado en formato HDF5\n",
    "modelo_cargado = load_model(\"modelo_sentimientos.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4882af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Realiza una predicci√≥n con el modelo cargado con el texto negativo\n",
    "prediction = modelo_cargado.predict(new_padded_negative)  \n",
    "\n",
    "sentimiento = \"Positivo\" if prediction[0] > 0.5 else \"Negativo\"\n",
    "\n",
    "print(f'\"{new_text_negative}\" ‚Üí Sentimiento: {sentimiento} ({prediction[0][0]:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realiza una predicci√≥n con el modelo cargado con el texto positivo\n",
    "prediction = modelo_cargado.predict(new_padded_positive)\n",
    "\n",
    "sentimiento = \"Positivo\" if prediction[0] > 0.5 else \"Negativo\"\n",
    "\n",
    "print(f'\"{new_text_positive}\" ‚Üí Sentimiento: {sentimiento} ({prediction[0][0]:.2f})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
