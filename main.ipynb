{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37230b5a",
   "metadata": {},
   "source": [
    "#### Realizaremos un modelo que identifique si un comentario es positivo o negativo con TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577544c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e0be693",
   "metadata": {},
   "source": [
    "1. importamos la librerías que nos permitirá hacer un buen manejo de lso datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas: Librería para manipulación y análisis de datos estructurados (DataFrames, CSV, etc.)\n",
    "import pandas as pd  \n",
    "\n",
    "# NumPy: Manejo eficiente de arreglos numéricos y cálculos matemáticos avanzados\n",
    "import numpy as np  \n",
    "\n",
    "# Matplotlib: Creación de gráficos y visualización de datos\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Deep Translator: Traducción automática de textos utilizando Google Translate\n",
    "from deep_translator import GoogleTranslator  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f057bc",
   "metadata": {},
   "source": [
    "2. ahora importaremos la librería que nos permitirá hacer el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1408234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow: Framework de aprendizaje automático que permite construir y entrenar redes neuronales\n",
    "import tensorflow as tf \n",
    "\n",
    "# Tokenizer: Convierte textos en secuencias numéricas para que el modelo las procese\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  \n",
    "\n",
    "# pad_sequences: Asegura que todas las secuencias tengan la misma longitud agregando ceros si es necesario\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  \n",
    "\n",
    "# train_test_split: Divide los datos en conjuntos de entrenamiento y prueba para evaluar el rendimiento del modelo\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# load_model: Carga un modelo previamente entrenado desde un archivo\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d39fa",
   "metadata": {},
   "source": [
    "3. cargamos el DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cdef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga un archivo CSV en un DataFrame de Pandas\n",
    "df = pd.read_csv('sentiment-analysis.csv')  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0965cd1c",
   "metadata": {},
   "source": [
    "4. traducimos todo los datos de la columna Text para trabajar con datos en español "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduce cada texto automáticamente al español\n",
    "df['Text'] = df['Text'].apply(lambda x: GoogleTranslator(source='auto', target='es').translate(x))  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame para verificar la traducción\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0efc011",
   "metadata": {},
   "source": [
    "5. una ves traducido los textos ahora hay que traducir las forma de sentimiento ( parte opcional )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduce cada etiqueta de sentimiento al español\n",
    "df['Sentiment'] = df['Sentiment'].apply(lambda x: GoogleTranslator(source='auto', target='es').translate(x))  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame para verificar la traducción\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71bfa81",
   "metadata": {},
   "source": [
    "6. por ultimo traducimos de donde es el usuario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e67189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduce automáticamente cada ubicación al español\n",
    "df['Location'] = df['Location'].apply(lambda x: GoogleTranslator(source='auto', target='es').translate(x))  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame para verificar la traducción\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b559e129",
   "metadata": {},
   "source": [
    "7. exportamos el DataFrame a csv para usarlo para el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda el DataFrame como un archivo CSV sin incluir el índice\n",
    "df.to_csv('análisis_de_sentimientos.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad4f75",
   "metadata": {},
   "source": [
    "8. una ves traducida y formateada al lenguaje que queremos lo leemos de vuelta para para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el archivo CSV en un DataFrame de Pandas\n",
    "df = pd.read_csv('análisis_de_sentimientos.csv')  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f986b15a",
   "metadata": {},
   "source": [
    "9. convertimos el tipo de sentimiento en Positivo a 1 Negativo a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb6b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte las etiquetas de sentimiento de texto a valores numéricos (1 para positivo, 0 para negativo)\n",
    "df['Sentiment'] = df['Sentiment'].map({'Positivo': 1, 'Negativo': 0})  \n",
    "\n",
    "# Muestra las primeras cinco filas del DataFrame para verificar la conversión\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09961c8d",
   "metadata": {},
   "source": [
    "10. debemos hacer que los valores del la columna Text se conviertan a números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define un tokenizador que usa hasta 5000 palabras y asigna \"<OOV>\" a palabras desconocidas\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")  \n",
    "\n",
    "# Ajusta el tokenizador usando los textos del dataset\n",
    "tokenizer.fit_on_texts(df[\"Text\"])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983be0f8",
   "metadata": {},
   "source": [
    "11. convertimos los valores de Text en una secuencia numérica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd87581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los textos en secuencias numéricas\n",
    "sequences = tokenizer.texts_to_sequences(df['Text'])  \n",
    "\n",
    "# Muestra las primeras cinco secuencias generadas\n",
    "sequences[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta la longitud de todas las secuencias agregando ceros al final cuando sea necesario\n",
    "padded_sequences = pad_sequences(sequences, padding='post')\n",
    "\n",
    "# Muestra las primeras cinco secuencias después de aplicar el padding\n",
    "padded_sequences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248a950",
   "metadata": {},
   "source": [
    "12. División en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sequences,  # 🔹 Datos de entrada: secuencias numéricas de los textos procesados\n",
    "    df[\"Sentiment\"],  # 🔹 Etiquetas de salida: 1 para positivo, 0 para negativo\n",
    "    test_size=0.2,  # 🔹 Reservamos el 20% de los datos para prueba y el 80% para entrenamiento\n",
    "    random_state=42  # 🔹 Usamos una semilla aleatoria para asegurar que la división sea reproducible en cada ejecución\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530cf745",
   "metadata": {},
   "source": [
    "13. Construcción del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa9d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Creación del modelo secuencial\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    #  Capa de Embedding: convierte palabras en vectores numéricos\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=5000,  # Define el tamaño del vocabulario (máximo 5000 palabras únicas)\n",
    "        output_dim=16,  # Especifica la dimensión de los vectores de palabras (cada palabra se representará con 16 valores)\n",
    "        input_length=padded_sequences.shape[1]  # Define la longitud esperada de las secuencias de entrada\n",
    "    ),\n",
    "\n",
    "    #  Global Average Pooling: reduce la dimensión del Embedding promediando los valores\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "\n",
    "    #  Capa completamente conectada (oculta) con 16 neuronas y activación ReLU\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "\n",
    "    #  Capa de salida con una única neurona y activación sigmoide para clasificación binaria\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b751e80",
   "metadata": {},
   "source": [
    "14. compilamos el modelo y mostramos el resumen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554513af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Compilamos el modelo antes de entrenarlo\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',  #  Función de pérdida utilizada en clasificación binaria; mide la diferencia entre la predicción y la etiqueta real\n",
    "    optimizer='adam',  #  Optimizador Adam ajusta los pesos del modelo para mejorar su precisión\n",
    "    metrics=['accuracy']  #  Se usa la métrica de precisión para evaluar el rendimiento durante el entrenamiento\n",
    ")\n",
    "\n",
    "# 🔹 Muestra la estructura del modelo, incluyendo el número de capas y parámetros\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3727a017",
   "metadata": {},
   "source": [
    "15. entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52263f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Entrenamos el modelo con los datos de entrenamiento\n",
    "history = model.fit(\n",
    "    X_train,  #  Datos de entrada para entrenamiento (secuencias de texto numerizadas)\n",
    "    y_train,  #  Etiquetas de salida para entrenamiento (1 = positivo, 0 = negativo)\n",
    "    epochs=100,  #  Número de épocas (veces que el modelo verá los datos para aprender)\n",
    "    validation_data=(X_test, y_test)  # 📌 Datos de validación para evaluar el rendimiento del modelo durante el entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbdb603",
   "metadata": {},
   "source": [
    "16. Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a86d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Evaluamos el modelo con los datos de prueba para medir su rendimiento\n",
    "loss, accuracy = model.evaluate(\n",
    "    X_test,  #  Conjunto de datos de prueba (secuencias numéricas)\n",
    "    y_test   #  Etiquetas reales de prueba (1 = positivo, 0 = negativo)\n",
    ")\n",
    "\n",
    "# 🔹 Imprimimos la precisión del modelo con dos decimales\n",
    "print(f\"Accuracy: {accuracy:.2f}\")  #  Muestra la precisión en porcentaje, indicando qué tan bien predice el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea805a44",
   "metadata": {},
   "source": [
    "17. hacemos el gráfico de perdida para para saber como le fue al modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d31be",
   "metadata": {},
   "source": [
    "#### Este gráfico representa la evolución de la pérdida del modelo durante el entrenamiento y la validación a lo largo de las épocas.\n",
    "\n",
    "- Eje X (Epochs): Muestra el número de épocas, es decir, la cantidad de veces que el modelo ha procesado el conjunto de datos para ajustar sus parámetros.\n",
    "\n",
    "- Eje Y (Loss): Representa el valor de la pérdida, que indica qué tan bien (o mal) el modelo está prediciendo los resultados. Un menor valor de pérdida \n",
    "significa un mejor ajuste del modelo.\n",
    "\n",
    "- Línea azul (\"Pérdida de Entrenamiento\"): Indica cómo disminuye la pérdida en el conjunto de entrenamiento a medida que el modelo aprende.\n",
    "\n",
    "- Línea roja (\"Pérdida de Validación\"): Muestra la pérdida en el conjunto de validación, que evalúa el rendimiento del modelo en datos que no ha visto \n",
    "durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la lista de épocas basada en la cantidad de iteraciones del entrenamiento\n",
    "epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Configuramos el tamaño de la figura para mejorar la visualización\n",
    "plt.figure(figsize=(30, 8))\n",
    "\n",
    "# Creamos el primer gráfico: evolución de la pérdida durante el entrenamiento y la validación\n",
    "plt.subplot(1, 2, 1)  # Dividimos la figura en 1 fila y 2 columnas, seleccionando la primera celda\n",
    "plt.plot(epochs, history.history['loss'], 'bo-', label='Pérdida de Entrenamiento')  # Trazamos la pérdida del conjunto de entrenamiento\n",
    "plt.plot(epochs, history.history['val_loss'], 'r*-', label='Pérdida de Validación')  # Trazamos la pérdida del conjunto de validación\n",
    "plt.xlabel('Epochs')  # Etiqueta del eje X (épocas del entrenamiento)\n",
    "plt.ylabel('Loss')  # Etiqueta del eje Y (valor de pérdida)\n",
    "plt.title('Training and Validation Loss')  # Título del gráfico\n",
    "plt.legend()  # Muestra la leyenda para diferenciar las líneas de entrenamiento y validación\n",
    "plt.grid()  # Agrega una cuadrícula para mejorar la visualización\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa956d6c",
   "metadata": {},
   "source": [
    "18. ahora hacemos el gráfico de precision "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a17178",
   "metadata": {},
   "source": [
    "#### Este gráfico representa la evolución de la precisión del modelo durante el entrenamiento y la validación a lo largo de las épocas.\n",
    "\n",
    "- Eje X (épocas): Indica el número de ciclos completos que el modelo ha realizado con los datos de entrenamiento. Cada época representa una pasada completa por el conjunto de datos.\n",
    "\n",
    "- Eje Y (nivel de precisión): Muestra la precisión del modelo, es decir, la proporción de predicciones correctas con respecto al total de ejemplos evaluados.\n",
    "\n",
    "- Línea azul (\"Precisión de Entrenamiento\"): Representa cómo mejora la precisión del modelo en el conjunto de datos utilizados para el entrenamiento. En general, esta línea debería aumentar con cada época.\n",
    "\n",
    "- Línea roja (\"Precisión de Validación\"): Indica la precisión del modelo al evaluar datos nuevos que no ha visto antes. Si esta línea comienza a disminuir mientras la precisión de entrenamiento sigue aumentando, puede ser una señal de sobreajuste.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b96584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos el tamaño de la figura para mejorar la visualización de la precisión\n",
    "plt.figure(figsize=(30, 8))\n",
    "\n",
    "# Creamos el segundo gráfico: evolución de la precisión durante el entrenamiento y la validación\n",
    "plt.subplot(1, 2, 2)  # Dividimos la figura en 1 fila y 2 columnas, seleccionando la segunda celda\n",
    "plt.plot(epochs, history.history['accuracy'], 'bo-', label='Precisión de Entrenamiento')  # Trazamos la precisión del conjunto de entrenamiento\n",
    "plt.plot(epochs, history.history['val_accuracy'], 'r*-', label='Precisión de Validación')  # Trazamos la precisión del conjunto de validación\n",
    "plt.xlabel('épocas')  # Etiqueta del eje X (épocas de entrenamiento)\n",
    "plt.ylabel('nivel de precisión')  # Etiqueta del eje Y (nivel de precisión)\n",
    "plt.title('Precision de entrenamiento y validaciones ')  # Título del gráfico\n",
    "plt.legend()  # Muestra la leyenda para diferenciar las líneas de entrenamiento y validación\n",
    "plt.grid()  # Agrega una cuadrícula para mejorar la lectura de los valores\n",
    "\n",
    "# Mostramos el gráfico en pantalla\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f8479",
   "metadata": {},
   "source": [
    "19. hacemos unos textos positivos y negativos para hacer uan predicción de prueba final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59aa4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un nuevo texto positivo para evaluar el modelo\n",
    "new_text_positive = \"Me encanta este producto, es increíble y funciona perfectamente.\"\n",
    "\n",
    "# Convertimos el texto en una secuencia numérica utilizando el tokenizador entrenado\n",
    "new_sequence = tokenizer.texts_to_sequences([new_text_positive])\n",
    "\n",
    "# Aplicamos padding a la secuencia para igualar la longitud esperada por el modelo\n",
    "new_padded_positive = pad_sequences(\n",
    "    new_sequence,  # Secuencia numérica generada a partir del texto\n",
    "    padding=\"post\",  # Agrega ceros al final si la secuencia es más corta que el tamaño esperado\n",
    "    maxlen=padded_sequences.shape[1]  # Define la longitud máxima basada en las secuencias utilizadas en el entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un nuevo texto negativo para evaluar el modelo\n",
    "new_text_negative = \"muy malo el producto no me gustó para nada\"\n",
    "\n",
    "# Convertimos el texto en una secuencia numérica utilizando el tokenizador entrenado\n",
    "new_sequence = tokenizer.texts_to_sequences([new_text_negative])\n",
    "\n",
    "# Aplicamos padding a la secuencia para igualar la longitud esperada por el modelo\n",
    "new_padded_negative = pad_sequences(\n",
    "    new_sequence,  # Secuencia numérica generada a partir del texto\n",
    "    padding=\"post\",  # Agrega ceros al final si la secuencia es más corta que el tamaño esperado\n",
    "    maxlen=padded_sequences.shape[1]  # Define la longitud máxima basada en las secuencias utilizadas en el entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e203e55",
   "metadata": {},
   "source": [
    "20. hacemos la predicción de los dos comentarios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d319869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la predicción utilizando el modelo entrenado\n",
    "prediction = model.predict(new_padded_positive)  # Genera una probabilidad de que el texto tenga un sentimiento positivo\n",
    "\n",
    "# Interpretamos la predicción: si el resultado es mayor a 0.5, se considera positivo; de lo contrario, negativo\n",
    "sentimiento = \"Positivo\" if prediction[0] > 0.5 else \"Negativo\"\n",
    "\n",
    "# Imprimimos el texto analizado junto con el sentimiento estimado y la probabilidad calculada\n",
    "print(f'\"{new_text_positive}\" → Sentimiento: {sentimiento} ({prediction[0][0]:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la predicción utilizando el modelo entrenado\n",
    "prediction = model.predict(new_padded_negative)  # Genera una probabilidad de que el texto tenga un sentimiento positivo\n",
    "\n",
    "# Interpretamos la predicción: si el resultado es mayor a 0.5, se considera positivo; de lo contrario, negativo\n",
    "sentimiento = \"Positivo\" if prediction[0] > 0.5 else \"Negativo\"\n",
    "\n",
    "# Imprimimos el texto analizado junto con el sentimiento estimado y la probabilidad calculada\n",
    "print(f'\"{new_text_negative}\" → Sentimiento: {sentimiento} ({prediction[0][0]:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b8d87",
   "metadata": {},
   "source": [
    "21. exportamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5254bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo en formato HDF5 (.h5)\n",
    "model.save(\"modelo_sentimientos.h5\")  \n",
    "# Guarda toda la arquitectura, pesos y configuración del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1161cfc",
   "metadata": {},
   "source": [
    "22. cargamos el modelo para probarlo de vuelta asi sabemos si funciona correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo guardado en formato HDF5\n",
    "modelo_cargado = load_model(\"modelo_sentimientos.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4882af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Realiza una predicción con el modelo cargado con el texto negativo\n",
    "prediction = modelo_cargado.predict(new_padded_negative)  \n",
    "\n",
    "sentimiento = \"Positivo\" if prediction[0] > 0.5 else \"Negativo\"\n",
    "\n",
    "print(f'\"{new_text_negative}\" → Sentimiento: {sentimiento} ({prediction[0][0]:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realiza una predicción con el modelo cargado con el texto positivo\n",
    "prediction = modelo_cargado.predict(new_padded_positive)\n",
    "\n",
    "sentimiento = \"Positivo\" if prediction[0] > 0.5 else \"Negativo\"\n",
    "\n",
    "print(f'\"{new_text_positive}\" → Sentimiento: {sentimiento} ({prediction[0][0]:.2f})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
